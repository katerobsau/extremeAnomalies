---
title: "Vignette"
format: html
editor: visual
---

```{r echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(here)
```

## Introduction

Para 1 - Automated testing is important for large scale data handling of observations and analysis of extreme events.

Para 2 - There are a suite of tests of available for quality assurance.

Para 3 - These do not necessarily guarantee the quality of the extreme observations. Known issues persist in this data that impact the analysis of extremes.

Para 4 - Here we provide methods and examples showing how to better assess the quality of the extreme rainfall observations.

## Data

- Write about GHCNDaily data 

- Write about rainfall variables - see readme https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt

PRCP = Precipitation (tenths of mm)

MDPR = Multiday precipitation total (tenths of mm; use with DAPR and 
	          DWPR, if available)

DAPR = Number of days included in the multiday precipiation 
	          total (MDPR)

DWPR = Number of days with non-zero precipitation included in 
	          multiday precipitation total (MDPR)

MDPR = Multiday precipitation total (tenths of mm; use with DAPR and 
	          DWPR, if available)


- Flags associated wtih automatic testing

QFLAG1     is the quality flag for the first day of the month.  There are fourteen possible values:

           Blank = did not fail any quality assurance check
           D     = failed duplicate check
           G     = failed gap check
           I     = failed internal consistency check
           K     = failed streak/frequent-value check
	         L     = failed check on length of multiday period 
           M     = failed megaconsistency check
           N     = failed naught check
           O     = failed climatological outlier check
           R     = failed lagged range check
           S     = failed spatial consistency check
           T     = failed temporal consistency check
           W     = temperature too warm for snow
           X     = failed bounds check
	   Z     = flagged as a result of an official Datzilla 
	           investigation

-   Where and how to download the data (rnoaa)

### Visualisation

```{r eval = TRUE, echo = FALSE}

fig_data_for_plot <- readRDS("../data/example_1974.rds")

fct_shapes = c(1, 16, 4, 13)
extreme_event_temporal_plot <- ggplot(fig_data_for_plot) +
  geom_point(aes(x = date, y = id,
                 col = prcp_combined, shape = prcp_type),
             size = 4, stroke = 1.15) +
  scale_shape_manual(name = "Obs Type",
                     values = fct_shapes) +
  scale_color_gradient(name = "Prcp (mm)", low = "skyblue", high = "navy") +
  xlab("Date") +
  ylab("Station Id") +
  ggtitle("Rainfall Observations", "Brisbane, Australia January 1974") +
  theme_bw()

extreme_event_temporal_plot
```

Caption: Daily rainfall observations in Brisbane, Australia. Solid circles are coloured by the measured precipitation. Empty circles show zero observations.A grey cross indicates missing data. Tagged accumulations, rainfall totals accumulated over multiple days, are shown with an empty circle and a cross. The final day in the accumulation period is coloured by the multiday total and the other days are coloured grey.

### Quality Issues 

On 26-01-1974 there was an extreme rainfall event in Brisbane, Australia, Figure XXXX. The majority of stations in this region recorded their annual maximum on this date. However, observations recorded at some stations are spatially inconsistent.

One of the stations has missing data on 26-01-1974. This station is shown with a cross. Observations were recorded on the days prior and missing observations are recorded in the days directly after. This suggests that the reason the observation is missing may be related to the extreme event, such as the station washing away. This missing observation is therefore likely to be a missing maximum.

Also on 26-01-1974 two observations are recorded as 0 mm. One of these
was flagged as spatially inconsistent by the GHCN-Daily quality control. The other was not. These zeros are clearly spurious given the surrounding rainfall. The true observations are likely to have been annual maxima for these stations.

There are also three tagged accumulations that cover 26-01-1974. The annual maximum for each of these stations is likely to have been recorded within the accumulation. Automatic identification of individual daily totals from an accumulation is challenging and we do not attempt it here.

Within this example there are also suspected untagged accumulations. Untagged accumulations occur when multiple days of rainfall are recorded as a single day. These types of observations can present as spurious maxima. An example of an untagged accumulation is the annual maximum observation of 240.4 mm recorded on 28-01-1974. On the four days prior to 28-01-1974, 0 mm of rainfall was recorded at the station. However, this period of zero recorded rainfall includes an extreme rainfall event on the 26-01-1974. Additionally, on
28-01-1974 the five closest stations recorded approximately 50 mm of rainfall compared with 240.4 mm. Given the observations at the surrounding stations from 24-01-1974 to 28-01-1974, this observation is clearly spurious and should have been flagged for quality.

Of the 27 stations in this example on 26-01-1974; we suspect that 3 maxima occurred within tagged accumulations, 1 station recorded missing data instead of a maximum and 2 observations were falsely recorded as zero instead of tagged accumulations. If the extremal observations are not treated appropriately during preprocessing, these observations will result in errors in the annual maximum observations. Whilst in general statistical methods will be robust to some errors within the data, care should be taken to identify as many systematic and prevalent sources of error as possible.

## Quality Control Issues

### Example Issue Write Up

-   Explain the problem
-   Identify and show examples of this quality control issue in the data
-   Provide R function(s) to address the issue
-   Provide suggested updated quality flag
-   Depending on the issue, demonstrate the impact of this on a basic GEV analysis with and without the fix.

<br><br>

### Outliers vs Extremes

#### Problem

- Current test assumes normality which is terrible for rainfall which is not normal
- Led to lots of false outlier flags 
- People should not filter their extreme data using these flags otherwise liable to remove true extrmes. 
- cite the automated QC paper 

### Examples ??? 

- Venezuala example (classic) 
- Don't have other examples in the data 
- How many "O"'s aren't really "O"'s  - false positive rate 
- Demonstrate this in the data somehow 

### R Solution 
- Don't filter the data by the "O" flag

### Proposed Solution 
- ??? if there is good coverage use spatial consistency checking / nearest neighbours ??? 
- meta data or historical newspapers 
- Need a better solution. 
 
### Fit a GEV with and without obs to show impact 

- Miralles and Davision trigger event paper

<!-- nbr_subset = # vector of ids # -->
<!-- min_num_nbrs = 4 -->
<!-- extreme rainfall - rough rule 20 km  -->

<br><br>

### Untagged Accumulations

### Flagging systematic missingness

-   (curious but aside - How does this carry through to the gridded data)

### Conclusions

### References
